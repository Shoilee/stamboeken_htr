# Handwritten Table to Knowledge Graph

This project converts handwritten table images into structured Knowledge Graphs (KGs) with **cell-level provenance**.

â— *Research Gap*: End-to-end processing of handwritten tables to structured Knowledge Graphs lacks reliability and traceability.

âœ… Solution: We present a traceable and explainable pipeline that:

1. Reconstructs tables from scanned images (TSR + HTR)
2. Maps text content to source cells using bounding boxes or cell indexes.
3. Extracts RDF triples with **cell-level provenance**


---

## Pipeline Steps

### 1. Table Reconstruction (TSR + HTR)

Convert image (e.g. jpg)â†’ structured table (e.g., HTML or 2D array)
```mermaid
graph TD;
   A((Image)) --> B[Cell Bounding Box Detection];
   A((Image)) --> C[Handwritten Text Recognition];
   B -- cell logical sequence <br/>cell bounding box coords --> D[Cell to Text Mapping]
   C --text lines with coords [pagexml]--> D;
   D --cell logical sequence + text content--> E[Construct Markup Table];
   E-->F((Table))

```
#### Cell Bounding Box Detection (using LORE-TSR)

- Add LORE-TSR as a Submodule

   ```bash
   git submodule add git@github.com:Shoilee/Image2TableBoundingBoxDetection.git
   cd Image2TableBoundingBoxDetection
   ```

   This repo uses a modified version of [LORE-TSR](https://github.com/AlibabaResearch/AdvancedLiterateMachineryDocumentUnderstanding/LORE-TSR)** designed to work on *CPU-only* systems (no CUDA required).

   > ğŸ’¡ *Note:* For full GPU (CUDA) support, use the original LORE-TSR repository.


- Create a conda environment:
   ```
   conda create --name Lore python=3.7
   conda activate Lore
   pip install -r requirements.txt
   ```

- Install DCNv2 from Scratch
   ```
   pip install Cython
   cd src/lib/models/networks/DCNv2
   chmod +x  *.sh
   ./make.sh
   ```

- Download Pretrained Model table cell detection model: model [ckpt_wireless](https://drive.google.com/file/d/1cBaewRwlZF1tIZovT49HpJZ5wlb3nSCw/view). Then create a model directory and move the downloaded file there:

   ```
   cd ../../../../../ 
   mkdir model
   ```

- Change the parameters such as model architecture, model path and input/output directory in `src/scripts/infer/demo_wireless.sh`

- Run the scripts
   ```
   cd src
   bash scripts/infer/demo_wireless.sh
   ```

#### Handwritten Text Recognition (using Loghi)

- Create the environment from the htr_env.yml file:
   ```bash
   conda env create -f htr_env.yml
   ```
- Pull loghi repo here 
   ```bash
   git clone git@github.com:knaw-huc/loghi.git
   ```
- Pull all the docker containers as per instructions
   ```bash
   docker pull loghi/docker.laypa
   docker pull loghi/docker.htr
   docker pull loghi/docker.loghi-tooling
   ```
- Go to: https://surfdrive.surf.nl/files/index.php/s/YA8HJuukIUKznSP and download 
   - a laypa model ("general") for detection of baselines and 
   - a loghi-htr model("float32-generic-2023-02-15") for HTR.

- Specify the parameter paths accordingly in `loghi/scripts/inference-pipeline.sh` (see original documentation of loghi)

- Run loghi to do HTR on table images
   ```
   python src/run_loghi.py
   ```


#### Reconstruct HTML table

   ```bash
   python src/reconstruct_table.py
   ```

---

### 2. Source-Aware Mapping

ğŸ“ Track table structure (bounding boxes or indexes) for each cell  
ğŸ”— Supports triple-level provenance using Semantic Web / Linked Data models

---

### 3. Information Extraction (IE) + KG Construction

ğŸ“ Extract values using:
- Regex patterns
- Large Language Models (LLMs)

ğŸ”„ Convert extracted information into RDF **triples**

# Set-up
#### 1. Install Mini-conda
Documentation: https://docs.anaconda.com/miniconda/


## Directory Structure

```
handwritten-table-kg/
â”‚
â”œâ”€â”€ ğŸ“ data/                    # Raw and intermediate data files
â”‚   â”œâ”€â”€ images/                 # Handwritten image files
â”‚   â”œâ”€â”€ htr                     # HTR files generated by Loghi 
|      |â”€â”€ page/                # PageXML
|      |â”€â”€ csv/                 # text equivalent text per line 
â”‚   â”œâ”€â”€ tables/                 # Structured table output (HTML, 2D arrays, CSV)
|      |â”€â”€ cells/               # output generated by LORE-TSR 
|      |â”€â”€ csv/                 # table in csv - cell logical secquence with text content
|      |â”€â”€ 2D/                  # table in 2D-array
|      |â”€â”€ html/                # table in html
â”‚   â”œâ”€â”€ lines/                  # HTRed text lines with coords (csv files)
â”‚   â”œâ”€â”€ triples/                # Final extracted RDF triples (TTL, JSON-LD, etc.)
â”‚   â””â”€â”€ examples/               # Example files for testing/demo
â”‚
â”œâ”€â”€ ğŸ“ models/                  # Pretrained models
â”‚   â”œâ”€â”€ laypa/                  # Layout analysis model
â”‚   â””â”€â”€ htr/                    # HTR model (e.g., float32-generic-2023-02-15)
â”‚
â”œâ”€â”€ ğŸ“ src/                     # All source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ reconstruct_table.py   # Image â†’ table reconstruction (TSR + HTR)
â”‚   â”œâ”€â”€ generate_html.py       # Converts structured table to HTML
â”‚   â”œâ”€â”€ extract_provenance.py  # Tracks source cells for triple-level provenance
â”‚   â”œâ”€â”€ extract_triples.py     # Regex/LLM-based triple extraction
â”‚   â””â”€â”€ utils.py               # Common utility functions
â”‚
â”œâ”€â”€ ğŸ“ scripts/                # Bash or python scripts for running pipeline
â”‚   â”œâ”€â”€ run_pipeline.sh        # End-to-end runner (bash)
â”‚   â”œâ”€â”€ run_loghi.py           # Loghi-based HTR runner
â”‚   â””â”€â”€ convert_to_triples.py  # Standalone triple generation
â”‚
â”œâ”€â”€ ğŸ“ notebooks/              # Jupyter notebooks for experimentation
â”‚   â””â”€â”€ demo.ipynb
â”‚
â”œâ”€â”€ ğŸ“ tests/                  # Unit and integration tests
â”‚   â””â”€â”€ test_extract_triples.py
â”‚
â”œâ”€â”€ ğŸ“„ environment.yml         # Conda environment file
â”œâ”€â”€ ğŸ“„ requirements.txt        # (Optional) for pip environments
â”œâ”€â”€ ğŸ“„ README.md               # Project description and usage
â””â”€â”€ ğŸ“„ .gitignore              # Git ignore rules

```