{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "268bd783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd80d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open(\"../data/labels/victor/NL-HaNA_2.10.50_45_0091.jpg.html\", 'r', encoding='utf-8') as f:\n",
    "    constructed_html = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca0c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(constructed_html, 'html.parser')\n",
    "\n",
    "rows = soup.find_all('tr')\n",
    "\n",
    "# --- Step 1: make a grid keeping track of rowspans ---\n",
    "logical_rows = []\n",
    "rowspans = {}  # {(col_idx): [remaining_rows, cell_content]}\n",
    "\n",
    "for r_idx, tr in enumerate(rows):\n",
    "    # Start with any carried over rowspans from previous rows\n",
    "    current_row = []\n",
    "    to_remove = []\n",
    "\n",
    "    # Fill carried-down cells first\n",
    "    for col_idx, (remaining, cell) in rowspans.items():\n",
    "        current_row.append(cell)\n",
    "        rowspans[col_idx][0] -= 1\n",
    "        if rowspans[col_idx][0] <= 0:\n",
    "            to_remove.append(col_idx)\n",
    "    for col_idx in to_remove:\n",
    "        del rowspans[col_idx]\n",
    "\n",
    "    # Now add new cells from this row\n",
    "    c_idx = 0\n",
    "    for td in tr.find_all('td'):\n",
    "        while any(k == c_idx for k in rowspans):  # skip columns occupied by carried cells\n",
    "            c_idx += 1\n",
    "        text = td.get_text(\" \", strip=True)\n",
    "        cell_id = td.get('id')\n",
    "        r_idx = int(td.get('row', r_idx))\n",
    "        c_idx = int(td.get('col', c_idx))\n",
    "        rowspan = int(td.get('rowspan', 1))\n",
    "        colspan = int(td.get('colspan', 1))\n",
    "\n",
    "        cell_data = {\n",
    "            'text': text,\n",
    "            'id': cell_id,\n",
    "            'row': r_idx,\n",
    "            'col': c_idx,\n",
    "            'rowspan': rowspan,\n",
    "            'colspan': colspan\n",
    "        }\n",
    "\n",
    "        # Place cell in current row\n",
    "        current_row.append(cell_data)\n",
    "\n",
    "        # Store for future rows if rowspan > 1\n",
    "        if rowspan > 1:\n",
    "            rowspans[c_idx] = [rowspan - 1, cell_data]\n",
    "\n",
    "        c_idx += colspan\n",
    "\n",
    "    logical_rows.append(current_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66b5357",
   "metadata": {},
   "source": [
    "# TODO: update the code, so that it can run for more than one person / row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f830f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_text(logical_rows, temp_path=\"../data/temp/\"):\n",
    "    import yaml\n",
    "\n",
    "    cell_spans = []     # list of dicts: {id, start, end}\n",
    "    row_text = \"\"       # concatenated text of the entire table\n",
    "    cursor = 0          # tracks current char offset\n",
    "\n",
    "    if not os.path.exists(temp_path):\n",
    "        os.makedirs(temp_path)\n",
    "\n",
    "    for i, row in enumerate(logical_rows):\n",
    "        if i != 1:\n",
    "            continue\n",
    "        for cell in row:\n",
    "            text = cell[\"text\"]\n",
    "            cid = cell[\"id\"]\n",
    "\n",
    "            start = cursor\n",
    "            end = start + len(text)\n",
    "\n",
    "            cell_spans.append({\n",
    "                \"id\": cid,\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "                \"text\": text\n",
    "            })\n",
    "\n",
    "            row_text += text + '\\n'\n",
    "            cursor = end\n",
    "        with open(os.path.join(temp_path , \"table_cells.yaml\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            yaml.dump(cell_spans, f, allow_unicode=True, sort_keys=False)\n",
    "\n",
    "        with open(os.path.join(temp_path, \"row.txt\"), \"w+\") as f:\n",
    "            f.write(row_text)\n",
    "\n",
    "generate_text(logical_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f0cefbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ontogpt', 'extract', '-i', 'row.txt', '-t', 'personbasicinfo.yaml', '-m', 'ollama/llama3', '-o', 'person.yaml'], returncode=0, stdout='', stderr='ERROR:root:Cannot find slot for here_are_the_extracted_entities_in_the_requested_format in Here are the extracted entities in the requested format:\\nERROR:root:Cannot find slot for here_is_the_text_split_into_fields_in_the_specified_format in Here is the text split into fields in the specified format:\\nERROR:root:Cannot find slot for note in Note: There is no mention of a Rochell entity in the provided text, which suggests that this might be an incorrect or incomplete entry.\\n')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_ontogpt(input_path=\"row.txt\",\n",
    "                template=\"personbasicinfo.yaml\",\n",
    "                model=\"ollama/llama3\",\n",
    "                output=\"person.yaml\",\n",
    "                cwd=None,\n",
    "                env=None):\n",
    "    \"\"\"\n",
    "    Run the same command as the %%bash cell from Python.\n",
    "    - cwd: working directory where row.txt and template live (e.g. \"../data/temp\")\n",
    "    - env: optional environment dict (os.environ copy + overrides)\n",
    "    Returns subprocess.CompletedProcess\n",
    "    \"\"\"\n",
    "    cmd = [\"ontogpt\", \"extract\", \"-i\", input_path, \"-t\", template, \"-m\", model, \"-o\", output]\n",
    "    proc = subprocess.run(cmd, cwd=cwd, env=env, capture_output=True, text=True)\n",
    "    if proc.returncode != 0:\n",
    "        print(\"ontogpt failed (rc={}):\".format(proc.returncode))\n",
    "        print(proc.stderr)\n",
    "        raise RuntimeError(\"ontogpt command failed\")\n",
    "    print(proc.stdout)\n",
    "    return proc\n",
    "\n",
    "# Example usage: run where generate_text wrote row.txt (default \"../data/temp/\")\n",
    "run_ontogpt(cwd=\"../data/temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59b80d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Updated YAML saved to ../data/temp/person.yaml\n"
     ]
    }
   ],
   "source": [
    "def map_text_spans_to_cell(yaml_path, cells_path:yaml):\n",
    "    def find_cell_for_span(start, spans):\n",
    "        \"\"\"\n",
    "        Return the cell_id whose text covers the character span starting at 'start'.\n",
    "        Span belongs to the cell where:  cell.start <= start < cell.end\n",
    "        \"\"\"\n",
    "        for item in spans:\n",
    "            if item[\"start\"] <= start < item[\"end\"]:\n",
    "                return item[\"id\"]\n",
    "        return None\n",
    "    \n",
    "    # ------------------------------\n",
    "    # 1. Load ONTOGPT output file\n",
    "    # ------------------------------\n",
    "    with open(yaml_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "\n",
    "    named_entities = data.get(\"named_entities\", [])\n",
    "\n",
    "    # ------------------------------\n",
    "    # 2. Load cell_spans index\n",
    "    # ------------------------------\n",
    "\n",
    "    with open(cells_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        cell_spans = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "    # ------------------------------\n",
    "    # 3. For each named entity, map span to cell id\n",
    "    # ------------------------------\n",
    "\n",
    "    for ent in named_entities:\n",
    "        spans = ent.get(\"original_spans\", [])\n",
    "        ent_cells = []\n",
    "\n",
    "        for span_str in spans:\n",
    "            try:\n",
    "                start, end = map(int, span_str.split(\":\"))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            cell_id = find_cell_for_span(start, cell_spans)\n",
    "            ent_cells.append(cell_id)\n",
    "\n",
    "        # Add new slot \"cell\"\n",
    "        if ent_cells:\n",
    "            # if only one span, store a single value\n",
    "            ent[\"cell\"] = ent_cells[0] if len(ent_cells) == 1 else ent_cells\n",
    "        else:\n",
    "            ent[\"cell\"] = None\n",
    "\n",
    "\n",
    "    # ------------------------------\n",
    "    # 4. Save updated YAML\n",
    "    # ------------------------------\n",
    "\n",
    "    output_path = yaml_path\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        yaml.dump(data, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "    print(\"✓ Updated YAML saved to\", output_path)\n",
    "\n",
    "map_text_spans_to_cell(\"../data/temp/person.yaml\", \"../data/temp/table_cells.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75838158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_yaml_to_json():\n",
    "    import yaml\n",
    "    import json\n",
    "    from copy import deepcopy\n",
    "\n",
    "\n",
    "    def load_yaml(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return yaml.safe_load(f)\n",
    "\n",
    "\n",
    "    def get_entity_for_value(raw_value, named_entities):\n",
    "        \"\"\"\n",
    "        Given a raw value like 'AUTO:Wageningen',\n",
    "        return the full named_entity dict (label, cell, original_spans),\n",
    "        or None if not found.\n",
    "        \"\"\"\n",
    "        if not isinstance(raw_value, str):\n",
    "            return None\n",
    "\n",
    "        for ent in named_entities:\n",
    "            if ent.get(\"id\") == raw_value:\n",
    "                return ent\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def process_field(value, named_entities):\n",
    "        \"\"\"\n",
    "        Converts a YAML value into normalized JSON format with:\n",
    "        - value\n",
    "        - cell\n",
    "        - original_spans\n",
    "        Handles nested dicts.\n",
    "        \"\"\"\n",
    "\n",
    "        # Case 1: nested dict → process each subfield recursively\n",
    "        if isinstance(value, dict):\n",
    "            processed = {}\n",
    "            for k, v in value.items():\n",
    "                processed[k] = process_field(v, named_entities)\n",
    "            return processed\n",
    "\n",
    "        # Case 2: literal field or AUTO reference\n",
    "        ent = get_entity_for_value(value, named_entities)\n",
    "\n",
    "        if ent:\n",
    "            # match found: use curated label + provenance\n",
    "            return {\n",
    "                \"value\": ent.get(\"label\"),\n",
    "                \"cell\": ent.get(\"cell\"),\n",
    "                \"original_spans\": ent.get(\"original_spans\")\n",
    "            }\n",
    "\n",
    "        # No entity match → raw literal value\n",
    "        return {\n",
    "            \"value\": value,\n",
    "            \"cell\": None,\n",
    "            \"original_spans\": None\n",
    "        }\n",
    "\n",
    "\n",
    "    def convert_yaml_to_person_json(data):\n",
    "        extracted = deepcopy(data[\"extracted_object\"])\n",
    "        named_entities = data[\"named_entities\"]\n",
    "\n",
    "        person = {}\n",
    "\n",
    "        # Process all fields dynamically\n",
    "        for key, value in extracted.items():\n",
    "            person[key] = process_field(value, named_entities)\n",
    "\n",
    "        return {\"persons\": [person]}\n",
    "\n",
    "\n",
    "    def write_json(path, obj):\n",
    "        with open(path, \"w+\", encoding=\"utf-8\") as f:\n",
    "            json.dump(obj, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # Example usage\n",
    "    # -------------------------------\n",
    "    if __name__ == \"__main__\":\n",
    "        yaml_path = \"../data/temp/person.yaml\"\n",
    "        json_out = \"../data/temp/person.json\"\n",
    "\n",
    "        data = load_yaml(yaml_path)\n",
    "        result = convert_yaml_to_person_json(data)\n",
    "        write_json(json_out, result)\n",
    "\n",
    "        print(json.dumps(result, indent=2, ensure_ascii=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htr_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
