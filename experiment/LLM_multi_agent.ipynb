{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408ce71a",
   "metadata": {},
   "source": [
    "First, activate conda environment:\n",
    "```bash\n",
    "conda activate NGTR\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b91e57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/sarah_shoilee/codeProjects/stamboekn_KE/Image2Table_LLM\n"
     ]
    }
   ],
   "source": [
    "import os, re, csv\n",
    "\n",
    "os.chdir(\"../Image2Table_LLM\")\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current directory:\", current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7cf02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_turn_conversation import call_LLM\n",
    "from LLM_key import llm_model\n",
    "from parse import extract_HTML, format_td\n",
    "from metric import TEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a382d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../data/images/NL-HaNA_2.10.50_45_0355.jpg\"\n",
    "image_name = os.path.basename(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eebd2c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Step 1: Detecting Table Cells\n",
      "\n",
      "To detect the table cells, we need to analyze the provided image. The image appears to be a scanned page from an old book, containing a table with handwritten text.\n",
      "\n",
      "Upon closer inspection, we can identify the table structure and the coordinates of each cell.\n",
      "\n",
      "The detected cell coordinates are as follows:\n",
      "```plaintext\n",
      "246,91;573,91;573,170;246,170 #c_1\n",
      "573,91;702,91;702,170;573,170 #c_2\n",
      "702,91;806,91;806,170;702,170 #c_3\n",
      "806,91;910,91;910,170;806,170 #c_4\n",
      "246,170;573,170;573,546;246,546 #c_5\n",
      "573,170;702,170;702,546;573,546 #c_6\n",
      "702,170;806,170;806,546;702,546 #c_7\n",
      "806,170;910,170;910,546;806,546 #c_8\n",
      "246,546;573,546;573,868;246,868 #c_9\n",
      "573,546;702,546;702,868;573,868 #c_10\n",
      "702,546;806,546;806,868;702,868 #c_11\n",
      "806,546;910,546;910,868;806,868 #c_12\n",
      "```\n",
      "\n",
      "The logical sequence mapping is as follows:\n",
      "```plaintext\n",
      "0, 0, 0, 0 #c_1\n",
      "0, 0, 1, 1 #c_2\n",
      "0, 0, 2, 2 #c_3\n",
      "0, 0, 3, 3 #c_4\n",
      "1, 1, 0, 0 #c_5\n",
      "1, 1, 1, 1 #c_6\n",
      "1, 1, 2, 2 #c_7\n",
      "1, 1, 3, 3 #c_8\n",
      "2, 2, 0, 0 #c_9\n",
      "2, 2, 1, 1 #c_10\n",
      "2, 2, 2, 2 #c_11\n",
      "2, 2, 3, 3 #c_12\n",
      "```\n",
      "\n",
      "### Step 2: Handwritten Text Recognition (HTR)\n",
      "\n",
      "To perform HTR, we need to analyze the handwritten text within each cell.\n",
      "\n",
      "The extracted text in pageXML format is as follows:\n",
      "```xml\n",
      "<Page>\n",
      " <TextRegion id=\"r1\">\n",
      " <TextLine id=\"l1\" x1=\"250\" y1=\"100\" x2=\"570\" y2=\"100\" x3=\"570\" y3=\"160\" x4=\"250\" y4=\"160\">\n",
      " <TextEquiv>\n",
      " <Unicode>Namen en Toenamen.</Unicode>\n",
      " </TextEquiv>\n",
      " </TextLine>\n",
      " <TextLine id=\"l2\" x1=\"580\" y1=\"100\" x2=\"700\" y2=\"100\" x3=\"700\" y3=\"160\" x4=\"580\" y4=\"160\">\n",
      " <TextEquiv>\n",
      " <Unicode>Namen der Ouders, datum van Geboorte, Geboorteplaats en laatste Woongplaats, en of dezelve gehuwd zijn en kinderen hebben.</Unicode>\n",
      " </TextEquiv>\n",
      " </TextLine>\n",
      " ...\n",
      " </TextRegion>\n",
      " <TextRegion id=\"r2\">\n",
      " <TextLine id=\"l3\" x1=\"250\" y1=\"200\" x2=\"400\" y2=\"200\" x3=\"400\" y3=\"250\" x4=\"250\" y4=\"250\">\n",
      " <TextEquiv>\n",
      " <Unicode>Wolf</Unicode>\n",
      " </TextEquiv>\n",
      " </TextLine>\n",
      " <TextLine id=\"l4\" x1=\"580\" y1=\"200\" x2=\"680\" y2=\"200\" x3=\"680\" y3=\"250\" x4=\"580\" y4=\"250\">\n",
      " <TextEquiv>\n",
      " <Unicode>Vader Isaac Swaart</Unicode>\n",
      " </TextEquiv>\n",
      " </TextLine>\n",
      " ...\n",
      " </TextRegion>\n",
      " ...\n",
      "</Page>\n",
      "```\n",
      "\n",
      "### Step 3: Reconstructing the HTML Table\n",
      "\n",
      "To reconstruct the HTML table, we need to compile the information from the detected cell coordinates and the extracted handwritten text.\n",
      "\n",
      "The reconstructed HTML table is as follows:\n",
      "```html\n",
      "<table>\n",
      " <thead>\n",
      " <tr>\n",
      " <td row=0 col=0 id=\"c_1\">Namen en Toenamen.</td>\n",
      " <td row=0 col=1 id=\"c_2\">Namen der Ouders, datum van Geboorte, Geboorteplaats en laatste Woongplaats, en of dezelve gehuwd zijn en kinderen hebben.</td>\n",
      " <td row=0 col=2 id=\"c_3\">Datums van aanstellingen in onderscheide Graven, van overgang naar andere korpsen, van bekomen Pensioen of Demissie en van Overlijden.</td>\n",
      " <td row=0 col=3 id=\"c_4\">In iedere graad gediend. Jaar | Maanden | Dagen</td>\n",
      " <td row=0 col=4 id=\"c_5\">Gedane veldtogten, bekomene wonden, uitstekende daden of bijzondere verrigtingen.</td>\n",
      " </tr>\n",
      " </thead>\n",
      " <tbody>\n",
      " <tr>\n",
      " <td row=1 col=0 id=\"c_6\">Wolf</td>\n",
      " <td row=1 col=1 id=\"c_7\">Vader Isaac Swaart Moeder Catharina Canters</td>\n",
      " <td row=1 col=2 id=\"c_8\"></td>\n",
      " <td row=1 col=3 id=\"c_9\"></td>\n",
      " <td row=1 col=4 id=\"c_10\"></td>\n",
      " </tr>\n",
      " <tr>\n",
      " <td row=2 col=0 id=\"c_11\">van Schack</td>\n",
      " <td row=2 col=1 id=\"c_12\">Vader Goert Arend Moeder Maria Canters</td>\n",
      " <td row=2 col=2 id=\"c_13\"></td>\n",
      " <td row=2 col=3 id=\"c_14\"></td>\n",
      " <td row=2 col=4 id=\"c_15\"></td>\n",
      " </tr>\n",
      " </tbody>\n",
      "</table>\n",
      "```\n",
      "\n",
      "Note that the empty cells are still included in the table, as per the instructions.\n"
     ]
    }
   ],
   "source": [
    "llm_response = call_LLM(image_path, model_name=llm_model, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70129478",
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_block = re.search(r\"coordinates.*?```plaintext(.*?)```\", llm_response, re.S | re.I)\n",
    "detected_lines = detected_block.group(1).strip().splitlines() if detected_block else []\n",
    "\n",
    "with open(os.path.join(\"../data/tables/cells/center\", image_name+'.txt'), \"w+\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for line in detected_lines:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        parts = line.split(\"#\")\n",
    "        polygon = parts[0].strip()\n",
    "        cell_id = \"#\" + parts[1].strip() if len(parts) > 1 else \"\"\n",
    "        writer.writerow([polygon, cell_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5e6a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_block = re.search(r\"logical sequence.*?```plaintext(.*?)```\", llm_response, re.S | re.I)\n",
    "logical_lines = logical_block.group(1).strip().splitlines() if logical_block else []\n",
    "\n",
    "with open(os.path.join(\"../data/tables/cells/logi\", image_name+'.txt'), \"w+\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"sequence\", \"cell_id\"])  # header\n",
    "    for line in logical_lines:\n",
    "        if not line.strip() or line.strip().startswith(\"</\"):\n",
    "            continue\n",
    "        parts = line.split(\"#\")\n",
    "        sequence = parts[0].strip()\n",
    "        cell_id = \"#\" + parts[1].strip() if len(parts) > 1 else \"\"\n",
    "        writer.writerow([sequence, cell_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f4ef9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_html = extract_HTML(llm_response)\n",
    "with open(os.path.join(\"../data/tables/html\", image_name+'.html'), 'w', encoding='utf-8') as f:\n",
    "    f.write(llm_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6705edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_TEDS(ground_truth_html, predicted_html):\n",
    "    predicted_html = format_td(predicted_html)\n",
    "    ground_truth_html = format_td(ground_truth_html)\n",
    "\n",
    "    teds = TEDS(structure_only=False)\n",
    "    teds_score = teds.evaluate(ground_truth_html, predicted_html)\n",
    "\n",
    "    teds_struct = TEDS(structure_only=True)\n",
    "    teds_struct_score = teds_struct.evaluate(ground_truth_html, predicted_html)\n",
    "    \n",
    "    print(f\"TEDS: {teds_score:.4f}\")\n",
    "    print(f\"TEDS-Struct: {teds_struct_score:.4f}\")\n",
    "\n",
    "    return teds_score, teds_struct_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58e1bd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEDS: 0.8377\n",
      "TEDS-Struct: 0.9286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8377424529245707, 0.9285714285714286)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(\"../data/labels\", image_name.replace('.jpg', '.html')), 'r', encoding='utf-8') as f:\n",
    "    label_html = f.read()\n",
    "\n",
    "calculate_TEDS(label_html, llm_html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a032de7",
   "metadata": {},
   "source": [
    "### Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b03c6e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/sarah_shoilee/codeProjects/stamboekn_KE\n"
     ]
    }
   ],
   "source": [
    "# Go outside the src directory\n",
    "os.chdir(\"..\")\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current directory:\", current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ffa2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(llm_html, \"html.parser\")\n",
    "table = soup.find(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b47c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "persons = []\n",
    "\n",
    "for row in table.find_all(\"tr\"):\n",
    "    cells = row.find_all(\"td\")\n",
    "\n",
    "    if not cells:\n",
    "        continue  # skip header or empty rows\n",
    "\n",
    "    person = {}\n",
    "    for cell in cells:\n",
    "        # preserve breaks as \\n\n",
    "        text = cell.get_text(separator=\"\\n\", strip=True)\n",
    "        \n",
    "        vader_match = re.search(r'Vader.?\\s+([^\\n,<]+)', text, re.IGNORECASE)\n",
    "        moeder_match = re.search(r'Moeder.?\\s+([^\\n,<]+)', text, re.IGNORECASE)\n",
    "        geboorte_datum_match = re.search(r'Geboorte.?\\s*Den\\s*([^\\n,<]+)', text, re.IGNORECASE)\n",
    "        geboorte_plaats_match = re.search(r'Geboortplaats.?\\s*([^\\n,<]+)', text, re.IGNORECASE)\n",
    "        laatste_woonplaats_match = re.search(r'Laatste\\s*Woonplaats.?\\s*([^\\n,<]+)', text, re.IGNORECASE)\n",
    "        \n",
    "        if vader_match:\n",
    "            person['vader'] = {'value': vader_match.group(1).strip(), 'cell': cell.get('id')}\n",
    "        if moeder_match:\n",
    "            person['moeder'] = {'value': moeder_match.group(1).strip(), 'cell': cell.get('id')}\n",
    "        if geboorte_datum_match:\n",
    "            person['geboorte_datum'] = {'value': geboorte_datum_match.group(1).strip(), 'cell': cell.get('id')}\n",
    "        if geboorte_plaats_match:\n",
    "            person['geboorte_plaats'] = {'value': geboorte_plaats_match.group(1).strip(), 'cell': cell.get('id')}\n",
    "        if laatste_woonplaats_match:\n",
    "            person['laatste_woonplaats'] = {'value': laatste_woonplaats_match.group(1).strip(), 'cell': cell.get('id')}\n",
    "\n",
    "    if person:\n",
    "        persons.append(person)\n",
    "\n",
    "json_obj = {\"persons\": persons}\n",
    "print(json.dumps(json_obj, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6799a8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"persons\": [\n",
      "    {\n",
      "      \"vader\": {\n",
      "        \"value\": \"Isaac Swaart Moeder Catharina Canters\",\n",
      "        \"cell\": \"c_7\"\n",
      "      },\n",
      "      \"moeder\": {\n",
      "        \"value\": \"Catharina Canters\",\n",
      "        \"cell\": \"c_7\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"vader\": {\n",
      "        \"value\": \"Goert Arend Moeder Maria Canters\",\n",
      "        \"cell\": \"c_12\"\n",
      "      },\n",
      "      \"moeder\": {\n",
      "        \"value\": \"Maria Canters\",\n",
      "        \"cell\": \"c_12\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "persons = []\n",
    "\n",
    "for row in table.find_all(\"tr\"):\n",
    "    cells = row.find_all(\"td\")\n",
    "\n",
    "    if not cells:\n",
    "        continue  # skip header or empty rows\n",
    "\n",
    "    person = {}\n",
    "    for cell in cells:\n",
    "        # preserve breaks as \\n\n",
    "        text = cell.get_text(separator=\"\\n\", strip=True)\n",
    "        \n",
    "        vader_match = re.search(r'Vader.?\\s+([^\\n,<]+)', text, re.IGNORECASE)\n",
    "        moeder_match = re.search(r'Moeder.?\\s+([^\\n,<]+)', text, re.IGNORECASE)\n",
    "        geboorte_datum_match = re.search(r'Geboorte.?\\s*Den\\s*([^\\n,<]+)', text, re.IGNORECASE)\n",
    "        geboorte_plaats_match = re.search(r'Geboortplaats.?\\s*([^\\n,<]+)', text, re.IGNORECASE)\n",
    "        laatste_woonplaats_match = re.search(r'Laatste\\s*Woonplaats.?\\s*([^\\n,<]+)', text, re.IGNORECASE)\n",
    "        \n",
    "        if vader_match:\n",
    "            person['vader'] = {'value': vader_match.group(1).strip(), 'cell': cell.get('id')}\n",
    "        if moeder_match:\n",
    "            person['moeder'] = {'value': moeder_match.group(1).strip(), 'cell': cell.get('id')}\n",
    "        if geboorte_datum_match:\n",
    "            person['geboorte_datum'] = {'value': geboorte_datum_match.group(1).strip(), 'cell': cell.get('id')}\n",
    "        if geboorte_plaats_match:\n",
    "            person['geboorte_plaats'] = {'value': geboorte_plaats_match.group(1).strip(), 'cell': cell.get('id')}\n",
    "        if laatste_woonplaats_match:\n",
    "            person['laatste_woonplaats'] = {'value': laatste_woonplaats_match.group(1).strip(), 'cell': cell.get('id')}\n",
    "\n",
    "    if person:\n",
    "        persons.append(person)\n",
    "\n",
    "json_obj = {\"persons\": persons}\n",
    "print(json.dumps(json_obj, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b6469da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/json/{image_name}.json\", \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(json_obj, json_file, ensure_ascii=False, indent=2)#!/usr/bin/env python3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d72df84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Person 1 ---\n",
      "vader: predicted='Isaac Swaart Moeder Catharina Canters' | ground_truth='Jacobus' | normalized_edit_distance=0.892\n",
      "moeder: predicted='Catharina Canters' | ground_truth='Catharina Ballert' | normalized_edit_distance=0.235\n",
      "Overall normalized edit distance for person 1: 0.564\n",
      "\n",
      "--- Person 2 ---\n",
      "vader: predicted='Goert Arend Moeder Maria Canters' | ground_truth='Coert Hendrik' | normalized_edit_distance=0.688\n",
      "moeder: predicted='Maria Canters' | ground_truth='Maria Van Onbeek' | normalized_edit_distance=0.438\n",
      "Overall normalized edit distance for person 2: 0.562\n",
      "\n",
      "Normalized edit distance over all persons and fields: 0.563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5630465023847377"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import calculate_normalized_information_distance\n",
    "\n",
    "with open(f\"data/json/{image_name}.json\", 'r', encoding='utf-8') as f:\n",
    "    constructed_html = json.load(f)\n",
    "with open(os.path.join(\"data/labels\", image_name.replace('.jpg', '.json')), 'r', encoding='utf-8') as f:\n",
    "    label_html = json.load(f)\n",
    "\n",
    "calculate_normalized_information_distance(constructed_html, label_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a942f",
   "metadata": {},
   "source": [
    "### KG construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json from file\n",
    "with open(f\"data/json/{image_name}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    json_obj = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3424a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTRUCT ASSERSION TRIPLES\n",
    "from rdflib import Graph, ConjunctiveGraph, Namespace, URIRef, Literal, RDF\n",
    "\n",
    "FOAF = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "EX = Namespace(\"http://example.org/ontology/\")\n",
    "PROV = Namespace(\"http://www.w3.org/ns/prov#\")\n",
    "\n",
    "cg = ConjunctiveGraph()\n",
    "cg.bind(\"foaf\", FOAF)\n",
    "cg.bind(\"ex\", EX)\n",
    "cg.bind(\"prov\", PROV)\n",
    "\n",
    "# Mapping from json keys to RDF predicates\n",
    "predicate_map = {\n",
    "    \"vader\": EX.vader,\n",
    "    \"moeder\": EX.moeder,\n",
    "    \"geboorte_datum\": EX.geboorteDatum,\n",
    "    \"geboorte_plaats\": EX.geboortePlaats,\n",
    "    \"laatste_woonplaats\": EX.laatsteWoonplaats\n",
    "}\n",
    "\n",
    "for idx, person in enumerate(json_obj[\"persons\"], start=1):\n",
    "    person_uri = URIRef(f\"http://example.org/person/{idx}\")\n",
    "    assertion_graph_uri = URIRef(\"http://example.org/assertion\")\n",
    "    assertion_graph = Graph(store=cg.store, identifier=assertion_graph_uri)\n",
    "    assertion_graph.add((person_uri, RDF.type, FOAF.Person))\n",
    "\n",
    "    provenance_graph_uri = URIRef(\"http://example.org/provenance\")\n",
    "    provenance_graph = Graph(store=cg.store, identifier=provenance_graph_uri)\n",
    "\n",
    "    for key, value_dict in person.items():\n",
    "        value = value_dict[\"value\"]\n",
    "        cell_id = value_dict[\"cell\"]\n",
    "        \n",
    "        predicate = predicate_map.get(key)\n",
    "        \n",
    "        # if cell_id is null, no named graph can be created\n",
    "        if not cell_id:\n",
    "            assertion_graph.add((person_uri, predicate, Literal(value)))\n",
    "            continue\n",
    "        \n",
    "        if predicate:\n",
    "            # Named graph for each cell\n",
    "            graph_uri = URIRef(f\"http://example.org/graph/{cell_id}\")\n",
    "            ng = Graph(store=cg.store, identifier=graph_uri)\n",
    "            ng.add((person_uri, predicate, Literal(value)))\n",
    "            \n",
    "\n",
    "cg.serialize(f\"data/triples/{image_name.replace('.jpg','')}_assersion.trig\", format='trig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4633769",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = \"2025-09-01T12:00:00Z\"  # Example end time, replace with actual time if needed\n",
    "start_time = \"2025-09-01T10:00:00Z\"  # Example start time, replace with actual time if needed\n",
    "\n",
    "def add_provenance_graph(html_path, coordinate_path, stamboek_nummer=image_name):\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_csv(coordinate_path, header=None)\n",
    "    print(df)\n",
    "\n",
    "    with open(html_path, 'r', encoding='utf-8') as f:\n",
    "        llm_html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(llm_html, \"html.parser\")\n",
    "\n",
    "    EX = Namespace(\"http://example.org/ontology/\")\n",
    "    IMG = Namespace(\"http://example.org/image_ontology/\")\n",
    "    RDF = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")  \n",
    "    RDFS = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "    PROV = Namespace(\"http://www.w3.org/ns/prov#\")\n",
    "    CSVW = Namespace(\"http://www.w3.org/ns/csvw#\")\n",
    "\n",
    "    # Create RDF graph\n",
    "    g = Graph()\n",
    "    g.bind(\"ex\", EX)\n",
    "    g.bind(\"img\", IMG)\n",
    "    g.bind(\"rdf\", RDF)\n",
    "    g.bind(\"rdfs\", RDFS)\n",
    "    g.bind(\"prov\", PROV)\n",
    "    g.csvw = (\"csvw\", CSVW)\n",
    "\n",
    "    for cell in soup.find_all(\"td\"):\n",
    "        cell_id = cell.get('id')\n",
    "        rows = cell.get('row')\n",
    "        cols = cell.get('col')\n",
    "        cell_number = int(cell_id.lstrip('#c_'))  # Assuming cell_id is like \"#c_1\", \"#2\", etc.\n",
    "        \n",
    "        try:\n",
    "            coords_points = df.iloc[cell_number - 1, 0]  # get polygon from dataframe\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving coordinates for cell {cell_id}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # cell uri\n",
    "        named_graph_uri = URIRef(f\"http://example.org/graph/{cell_id}\")\n",
    "        cell_uri = URIRef(f\"http://example.org/id/{cell_id}\")\n",
    "        provenance_graph.add((named_graph_uri, PROV.wasDerivedFrom, cell_uri))\n",
    "        g.add((cell_uri, RDF.type, PROV.Entity))\n",
    "        g.add((cell_uri, RDFS.label, Literal(f\"Cell {cell_id} from {stamboek_nummer}\")))\n",
    "            \n",
    "        g.add((cell_uri, RDF.type, CSVW.Cell))\n",
    "        g.add((cell_uri, CSVW.rowNumber, Literal(rows)))\n",
    "        g.add((cell_uri, CSVW.columnNumber, Literal(cols)))\n",
    "        g.add((cell_uri, EX.ImageRegion, Literal(coords_points)))\n",
    "\n",
    "        # agents\n",
    "        agent_1 = URIRef(\"http://example.org/agent/1\")\n",
    "        g.add((agent_1, RDF.type, PROV.Agent))\n",
    "        g.add((agent_1, RDFS.label, Literal(\"Sarah Shoilee\")))\n",
    "        g.add((named_graph_uri, PROV.wasAttributedTo, agent_1))\n",
    "        project_agent = URIRef(\"http://example.org/agent/2\")\n",
    "        g.add((project_agent, RDF.type, PROV.Agent))\n",
    "        g.add((project_agent, RDFS.label, Literal(\"Pressing Matter Project\")))\n",
    "        g.add((agent_1, PROV.actedOnBehalfOf, project_agent))\n",
    "\n",
    "        # activity\n",
    "        stamboekenKGConstructionactivity = URIRef(f\"http://example.org/activity/stamboekenKGConstructionactivity/{cell_id}\")\n",
    "        tableConstructionactivity = URIRef(f\"http://example.org/activity/TableExtraction/{cell_id}\")\n",
    "        informationExtractionactivity = URIRef(f\"http://example.org/activity/InformationExtraction/{cell_id}\")\n",
    "        KGConstructionactivity = URIRef(f\"http://example.org/activity/KGConstruction/{cell_id}\")\n",
    "            \n",
    "        g.add((stamboekenKGConstructionactivity, RDF.type, PROV.Activity))\n",
    "        g.add((named_graph_uri, PROV.wasGeneratedBy, stamboekenKGConstructionactivity))\n",
    "        g.add((stamboekenKGConstructionactivity, PROV.wasAssociatedWith, agent_1))\n",
    "        g.add((stamboekenKGConstructionactivity, PROV.wasInformedBy, tableConstructionactivity))\n",
    "        g.add((tableConstructionactivity, RDF.type, PROV.Activity))\n",
    "        g.add((stamboekenKGConstructionactivity, PROV.wasInformedBy, informationExtractionactivity))\n",
    "        g.add((informationExtractionactivity, RDF.type, PROV.Activity))\n",
    "        g.add((informationExtractionactivity, PROV.used, cell_uri))\n",
    "        g.add((stamboekenKGConstructionactivity, PROV.wasInformedBy, KGConstructionactivity))\n",
    "        g.add((KGConstructionactivity, RDF.type, PROV.Activity))\n",
    "        g.add((KGConstructionactivity, PROV.used, cell_uri))\n",
    "\n",
    "        g.add((stamboekenKGConstructionactivity,PROV.endedAtTime, Literal(end_time)))\n",
    "        g.add((stamboekenKGConstructionactivity,PROV.startedAtTime, Literal(start_time)))\n",
    "\n",
    "        # Create a Table instance URI\n",
    "        table_uri = URIRef(f\"http://example.org/Table/{cell_id}\")\n",
    "        g.add((table_uri, RDF.type, PROV.Entity))\n",
    "        g.add((table_uri, RDF.type, CSVW.Table))\n",
    "        g.add((table_uri, PROV.wasGeneratedBy, tableConstructionactivity))\n",
    "        g.add((cell_uri, PROV.wasDerivedFrom, table_uri))\n",
    "            \n",
    "        # stamboeken\n",
    "        stamboek_uri = URIRef(f\"http://example.org/stamboek/{stamboek_nummer}\")\n",
    "        g.add((stamboek_uri, RDF.type, PROV.Entity))\n",
    "        g.add((tableConstructionactivity, PROV.used, stamboek_uri))\n",
    "        g.add((table_uri, PROV.wasDerivedFrom, stamboek_uri))\n",
    "        national_archives = URIRef(\"http://example.org/agent/3\")\n",
    "        g.add((national_archives, RDF.type, PROV.Agent))\n",
    "        g.add((national_archives, RDFS.label, Literal(\"Nationaal Archief\")))\n",
    "        g.add((stamboek_uri, PROV.wasAttributedTo, national_archives))\n",
    "    \n",
    "    g.serialize(f\"data/triples/{image_name.replace('.jpg','')}_provenance.ttl\", format='ttl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff761c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(\"data/tables/cells/center\", image_name+'.txt')\n",
    "table_path = os.path.join(\"data/tables/html\", image_name+'.html')\n",
    "\n",
    "add_provenance_graph(table_path, csv_path, stamboek_nummer=image_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGTR",
   "language": "python",
   "name": "ngtr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
