{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a4d6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/sarah_shoilee/codeProjects/stamboekn_KE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Go outside the src directory\n",
    "os.chdir(\"..\")\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current directory:\", current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ab9f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NL-HaNA_2.10.50_45_0355'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"data/images/NL-HaNA_2.10.50_45_0355.jpg\"\n",
    "image_name = os.path.basename(image_path)\n",
    "base_name = os.path.splitext(image_name)[0]\n",
    "base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af0e2ce",
   "metadata": {},
   "source": [
    "RUN LORE and HTR First:\n",
    "```bash\n",
    "cd Image2TableBoundingBoxDetection\n",
    "cd src \n",
    "conda deactivate\n",
    "conda activate LORE\n",
    "bash scripts/infer/demo_wireless.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bfddc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image: NL-HaNA_2.10.50_45_0355.jpg\n"
     ]
    }
   ],
   "source": [
    "cells_bounding_box = f\"data/tables/cells/center/{image_name}.txt\"\n",
    "cells_structure = f\"data/tables/cells/logi/{image_name}.txt\"\n",
    "page_file = f\"data/htr/page/{base_name}.xml\"\n",
    "json_file = f\"data/tables/json/{image_name}.jsonl\"\n",
    "\n",
    "print(f\"\\nProcessing image: {image_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac64e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table structure built successfully.\n",
      "Table reconstructed and saved to data/tables/html/NL-HaNA_2.10.50_45_0355.jpg.html\n"
     ]
    }
   ],
   "source": [
    "from src.reconstruct_table import main as reconstruct_table\n",
    "reconstruct_table(cells_bounding_box, cells_structure, page_file, json_file, image_name, wired=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058c4175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Image2Table_LLM.parse import format_td\n",
    "from Image2Table_LLM.metric import TEDS\n",
    "\n",
    "def calculate_TEDS(ground_truth_html, predicted_html):\n",
    "    predicted_html = format_td(predicted_html)\n",
    "    ground_truth_html = format_td(ground_truth_html)\n",
    "\n",
    "    teds = TEDS(structure_only=False)\n",
    "    teds_score = teds.evaluate(ground_truth_html, predicted_html)\n",
    "\n",
    "    teds_struct = TEDS(structure_only=True)\n",
    "    teds_struct_score = teds_struct.evaluate(ground_truth_html, predicted_html)\n",
    "    \n",
    "    print(f\"TEDS: {teds_score:.4f}\")\n",
    "    print(f\"TEDS-Struct: {teds_struct_score:.4f}\")\n",
    "\n",
    "    return teds_score, teds_struct_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba5ae2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEDS: 0.4946\n",
      "TEDS-Struct: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.49464379570691897, 0.6666666666666667)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(\"data/tables/html/\", image_name+'.html'), 'r', encoding='utf-8') as f:\n",
    "    constructed_html = f.read()\n",
    "\n",
    "with open(os.path.join(\"data/labels\", image_name.replace('.jpg', '.html')), 'r', encoding='utf-8') as f:\n",
    "    label_html = f.read()\n",
    "\n",
    "calculate_TEDS(label_html, constructed_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8910e2a6",
   "metadata": {},
   "source": [
    "### Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d634d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(constructed_html, 'html.parser')\n",
    "\n",
    "rows = soup.find_all('tr')\n",
    "\n",
    "# --- Step 1: make a grid keeping track of rowspans ---\n",
    "logical_rows = []\n",
    "rowspans = {}  # {(col_idx): [remaining_rows, cell_content]}\n",
    "\n",
    "for r_idx, tr in enumerate(rows):\n",
    "    # Start with any carried over rowspans from previous rows\n",
    "    current_row = []\n",
    "    to_remove = []\n",
    "\n",
    "    # Fill carried-down cells first\n",
    "    for col_idx, (remaining, cell) in rowspans.items():\n",
    "        current_row.append(cell)\n",
    "        rowspans[col_idx][0] -= 1\n",
    "        if rowspans[col_idx][0] <= 0:\n",
    "            to_remove.append(col_idx)\n",
    "    for col_idx in to_remove:\n",
    "        del rowspans[col_idx]\n",
    "\n",
    "    # Now add new cells from this row\n",
    "    c_idx = 0\n",
    "    for td in tr.find_all('td'):\n",
    "        while any(k == c_idx for k in rowspans):  # skip columns occupied by carried cells\n",
    "            c_idx += 1\n",
    "        text = td.get_text(\" \", strip=True)\n",
    "        cell_id = td.get('id')\n",
    "        r_idx = int(td.get('row', r_idx))\n",
    "        c_idx = int(td.get('col', c_idx))\n",
    "        rowspan = int(td.get('rowspan', 1))\n",
    "        colspan = int(td.get('colspan', 1))\n",
    "\n",
    "        cell_data = {\n",
    "            'text': text,\n",
    "            'id': cell_id,\n",
    "            'row': r_idx,\n",
    "            'col': c_idx,\n",
    "            'rowspan': rowspan,\n",
    "            'colspan': colspan\n",
    "        }\n",
    "\n",
    "        # Place cell in current row\n",
    "        current_row.append(cell_data)\n",
    "\n",
    "        # Store for future rows if rowspan > 1\n",
    "        if rowspan > 1:\n",
    "            rowspans[c_idx] = [rowspan - 1, cell_data]\n",
    "\n",
    "        c_idx += colspan\n",
    "\n",
    "    logical_rows.append(current_row)\n",
    "\n",
    "\n",
    "with open(\"output.txt\", \"w+\", encoding=\"utf-8\") as f:\n",
    "    for i, row in enumerate(logical_rows):\n",
    "        f.write(f\"Row {i+1}:\\n\")\n",
    "        for cell in row:\n",
    "            f.write(\n",
    "                    f\"  id={cell.get('id')}, \"\n",
    "                    f\"row={cell.get('row')}, \"\n",
    "                    f\"col={cell.get('col')}, \"\n",
    "                    f\"text={cell.get('text')}\\n\"\n",
    "                )\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e6672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"persons\": [\n",
      "    {\n",
      "      \"vader\": {\n",
      "        \"value\": \"Jacobus\",\n",
      "        \"cell\": \"4\"\n",
      "      },\n",
      "      \"moeder\": {\n",
      "        \"value\": \"Catharina Gullart\",\n",
      "        \"cell\": \"4\"\n",
      "      },\n",
      "      \"geboorte_datum\": {\n",
      "        \"value\": \"9 october 1775\",\n",
      "        \"cell\": \"4\"\n",
      "      },\n",
      "      \"geboorte_plaats\": {\n",
      "        \"value\": \"Schoonhoven\",\n",
      "        \"cell\": \"4\"\n",
      "      },\n",
      "      \"laatste_woonplaats\": {\n",
      "        \"value\": \"Buille\",\n",
      "        \"cell\": \"4\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"vader\": {\n",
      "        \"value\": \"Jacobus\",\n",
      "        \"cell\": \"4\"\n",
      "      },\n",
      "      \"moeder\": {\n",
      "        \"value\": \"Catharina Gullart\",\n",
      "        \"cell\": \"4\"\n",
      "      },\n",
      "      \"geboorte_datum\": {\n",
      "        \"value\": \"9 october 1775\",\n",
      "        \"cell\": \"4\"\n",
      "      },\n",
      "      \"geboorte_plaats\": {\n",
      "        \"value\": \"Schoonhoven\",\n",
      "        \"cell\": \"4\"\n",
      "      },\n",
      "      \"laatste_woonplaats\": {\n",
      "        \"value\": \"Buille\",\n",
      "        \"cell\": \"4\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"vader\": {\n",
      "        \"value\": null,\n",
      "        \"cell\": null\n",
      "      },\n",
      "      \"moeder\": {\n",
      "        \"value\": \"Maria van Arbeek\",\n",
      "        \"cell\": \"16\"\n",
      "      },\n",
      "      \"geboorte_datum\": {\n",
      "        \"value\": \"23 December 1771\",\n",
      "        \"cell\": \"16\"\n",
      "      },\n",
      "      \"geboorte_plaats\": {\n",
      "        \"value\": \"sslage\",\n",
      "        \"cell\": \"16\"\n",
      "      },\n",
      "      \"laatste_woonplaats\": {\n",
      "        \"value\": \"SHlage\",\n",
      "        \"cell\": \"16\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from src.person_info_extraction import extract_info_regex, extract_info_LLM\n",
    "\n",
    "persons = []\n",
    "\n",
    "for i, row in enumerate(logical_rows):\n",
    "    person = {}\n",
    "        \n",
    "    # print(generate_prompt(cells))\n",
    "    person = json.loads(extract_info_LLM(row))\n",
    "    if all(v['value']==None for v in person.values()):\n",
    "        continue\n",
    "\n",
    "    if person:\n",
    "        persons.append(person)\n",
    "\n",
    "json_obj = {\"persons\": persons}\n",
    "print(json.dumps(json_obj, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b4e447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/json/{image_name}.json\", \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(json_obj, json_file, ensure_ascii=False, indent=2)#!/usr/bin/env python3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a34a41ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5414404223227752)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import best_match_similarity\n",
    "# from src.metrics import calculate_normalized_information_distance\n",
    "\n",
    "with open(f\"data/json/{image_name}.json\", 'r', encoding='utf-8') as f:\n",
    "    constructed_html = json.load(f)\n",
    "with open(os.path.join(\"data/labels\", image_name.replace('.jpg', '.json')), 'r', encoding='utf-8') as f:\n",
    "    label_html = json.load(f)\n",
    "\n",
    "# calculate_normalized_information_distance(constructed_html, label_html)\n",
    "best_match_similarity(constructed_html.get(\"persons\", []), label_html.get(\"persons\", []))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9b17d3",
   "metadata": {},
   "source": [
    "### KG construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bd4946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json from file\n",
    "with open(f\"data/json/{image_name}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    json_obj = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "624a7369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jg/8kz6nb554_3dz1_0swrmdw480000gn/T/ipykernel_74602/2391772286.py:8: DeprecationWarning: ConjunctiveGraph is deprecated, use Dataset instead.\n",
      "  cg = ConjunctiveGraph()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N52e315c8a22e473bb5e138e688a31ef9 (<class 'rdflib.graph.ConjunctiveGraph'>)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONSTRUCT ASSERSION TRIPLES\n",
    "from rdflib import Graph, ConjunctiveGraph, Namespace, URIRef, Literal, RDF\n",
    "\n",
    "FOAF = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "EX = Namespace(\"http://example.org/ontology/\")\n",
    "PROV = Namespace(\"http://www.w3.org/ns/prov#\")\n",
    "\n",
    "cg = ConjunctiveGraph()\n",
    "cg.bind(\"foaf\", FOAF)\n",
    "cg.bind(\"ex\", EX)\n",
    "cg.bind(\"prov\", PROV)\n",
    "\n",
    "# Mapping from json keys to RDF predicates\n",
    "predicate_map = {\n",
    "    \"vader\": EX.vader,\n",
    "    \"moeder\": EX.moeder,\n",
    "    \"geboorte_datum\": EX.geboorteDatum,\n",
    "    \"geboorte_plaats\": EX.geboortePlaats,\n",
    "    \"laatste_woonplaats\": EX.laatsteWoonplaats\n",
    "}\n",
    "\n",
    "for idx, person in enumerate(json_obj[\"persons\"], start=1):\n",
    "    person_uri = URIRef(f\"http://example.org/person/{idx}\")\n",
    "    assertion_graph_uri = URIRef(\"http://example.org/assertion\")\n",
    "    assertion_graph = Graph(store=cg.store, identifier=assertion_graph_uri)\n",
    "    assertion_graph.add((person_uri, RDF.type, FOAF.Person))\n",
    "\n",
    "    provenance_graph_uri = URIRef(\"http://example.org/provenance\")\n",
    "    provenance_graph = Graph(store=cg.store, identifier=provenance_graph_uri)\n",
    "\n",
    "    for key, value_dict in person.items():\n",
    "        value = value_dict[\"value\"]\n",
    "        cell_id = value_dict[\"cell\"]\n",
    "        \n",
    "        predicate = predicate_map.get(key)\n",
    "        \n",
    "        # if cell_id is null, no named graph can be created\n",
    "        if not cell_id:\n",
    "            assertion_graph.add((person_uri, predicate, Literal(value)))\n",
    "            continue\n",
    "        \n",
    "        if predicate:\n",
    "            # Named graph for each cell\n",
    "            graph_uri = URIRef(f\"http://example.org/graph/{cell_id}\")\n",
    "            ng = Graph(store=cg.store, identifier=graph_uri)\n",
    "            ng.add((person_uri, predicate, Literal(value)))\n",
    "            \n",
    "\n",
    "cg.serialize(f\"data/triples/{image_name.replace('.jpg','')}_assersion.trig\", format='trig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28af9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = \"2025-09-01T12:00:00Z\"  # Example end time, replace with actual time if needed\n",
    "start_time = \"2025-09-01T10:00:00Z\"  # Example start time, replace with actual time if needed\n",
    "\n",
    "def add_provenance_graph(html_path, coordinate_path, stamboek_nummer=image_name):\n",
    "    import pandas as pd\n",
    "\n",
    "    # csv read file\n",
    "    with open(coordinate_path, \"r\") as coordinate_lines:\n",
    "        coordinate_lines = coordinate_lines.readlines()\n",
    "    # df = pd.read_csv(coordinate_path, header=None)\n",
    "    \n",
    "    with open(html_path, 'r', encoding='utf-8') as f:\n",
    "        llm_html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(llm_html, \"html.parser\")\n",
    "\n",
    "    EX = Namespace(\"http://example.org/ontology/\")\n",
    "    IMG = Namespace(\"http://example.org/image_ontology/\")\n",
    "    RDF = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")  \n",
    "    RDFS = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "    PROV = Namespace(\"http://www.w3.org/ns/prov#\")\n",
    "    CSVW = Namespace(\"http://www.w3.org/ns/csvw#\")\n",
    "\n",
    "    # Create RDF graph\n",
    "    g = Graph()\n",
    "    g.bind(\"ex\", EX)\n",
    "    g.bind(\"img\", IMG)\n",
    "    g.bind(\"rdf\", RDF)\n",
    "    g.bind(\"rdfs\", RDFS)\n",
    "    g.bind(\"prov\", PROV)\n",
    "    g.csvw = (\"csvw\", CSVW)\n",
    "\n",
    "    for cell in soup.find_all(\"td\"):\n",
    "        cell_id = cell.get('id')\n",
    "        rows = cell.get('row')\n",
    "        cols = cell.get('col')\n",
    "\n",
    "        if not cell_id:\n",
    "            # when cell is None or Merged\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            coords_line = coordinate_lines[int(cell_id)]\n",
    "            coords_points = coords_line.strip().split(\";\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving coordinates for cell {cell_id}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # cell uri\n",
    "        named_graph_uri = URIRef(f\"http://example.org/graph/{cell_id}\")\n",
    "        cell_uri = URIRef(f\"http://example.org/id/{cell_id}\")\n",
    "        provenance_graph.add((named_graph_uri, PROV.wasDerivedFrom, cell_uri))\n",
    "        g.add((cell_uri, RDF.type, PROV.Entity))\n",
    "        g.add((cell_uri, RDFS.label, Literal(f\"Cell {cell_id} from {stamboek_nummer}\")))\n",
    "            \n",
    "        g.add((cell_uri, RDF.type, CSVW.Cell))\n",
    "        g.add((cell_uri, CSVW.rowNumber, Literal(rows)))\n",
    "        g.add((cell_uri, CSVW.columnNumber, Literal(cols)))\n",
    "        g.add((cell_uri, EX.ImageRegion, Literal(coords_points)))\n",
    "\n",
    "        # agents\n",
    "        agent_1 = URIRef(\"http://example.org/agent/1\")\n",
    "        g.add((agent_1, RDF.type, PROV.Agent))\n",
    "        g.add((agent_1, RDFS.label, Literal(\"Sarah Shoilee\")))\n",
    "        g.add((named_graph_uri, PROV.wasAttributedTo, agent_1))\n",
    "        project_agent = URIRef(\"http://example.org/agent/2\")\n",
    "        g.add((project_agent, RDF.type, PROV.Agent))\n",
    "        g.add((project_agent, RDFS.label, Literal(\"Pressing Matter Project\")))\n",
    "        g.add((agent_1, PROV.actedOnBehalfOf, project_agent))\n",
    "\n",
    "        # activity\n",
    "        stamboekenKGConstructionactivity = URIRef(f\"http://example.org/activity/stamboekenKGConstructionactivity/{cell_id}\")\n",
    "        tableConstructionactivity = URIRef(f\"http://example.org/activity/TableExtraction/{cell_id}\")\n",
    "        informationExtractionactivity = URIRef(f\"http://example.org/activity/InformationExtraction/{cell_id}\")\n",
    "        KGConstructionactivity = URIRef(f\"http://example.org/activity/KGConstruction/{cell_id}\")\n",
    "            \n",
    "        g.add((stamboekenKGConstructionactivity, RDF.type, PROV.Activity))\n",
    "        g.add((named_graph_uri, PROV.wasGeneratedBy, stamboekenKGConstructionactivity))\n",
    "        g.add((stamboekenKGConstructionactivity, PROV.wasAssociatedWith, agent_1))\n",
    "        g.add((stamboekenKGConstructionactivity, PROV.wasInformedBy, tableConstructionactivity))\n",
    "        g.add((tableConstructionactivity, RDF.type, PROV.Activity))\n",
    "        g.add((stamboekenKGConstructionactivity, PROV.wasInformedBy, informationExtractionactivity))\n",
    "        g.add((informationExtractionactivity, RDF.type, PROV.Activity))\n",
    "        g.add((informationExtractionactivity, PROV.used, cell_uri))\n",
    "        g.add((stamboekenKGConstructionactivity, PROV.wasInformedBy, KGConstructionactivity))\n",
    "        g.add((KGConstructionactivity, RDF.type, PROV.Activity))\n",
    "        g.add((KGConstructionactivity, PROV.used, cell_uri))\n",
    "\n",
    "        g.add((stamboekenKGConstructionactivity,PROV.endedAtTime, Literal(end_time)))\n",
    "        g.add((stamboekenKGConstructionactivity,PROV.startedAtTime, Literal(start_time)))\n",
    "\n",
    "        # Create a Table instance URI\n",
    "        table_uri = URIRef(f\"http://example.org/Table/{cell_id}\")\n",
    "        g.add((table_uri, RDF.type, PROV.Entity))\n",
    "        g.add((table_uri, RDF.type, CSVW.Table))\n",
    "        g.add((table_uri, PROV.wasGeneratedBy, tableConstructionactivity))\n",
    "        g.add((cell_uri, PROV.wasDerivedFrom, table_uri))\n",
    "            \n",
    "        # stamboeken\n",
    "        stamboek_uri = URIRef(f\"http://example.org/stamboek/{stamboek_nummer}\")\n",
    "        g.add((stamboek_uri, RDF.type, PROV.Entity))\n",
    "        g.add((tableConstructionactivity, PROV.used, stamboek_uri))\n",
    "        g.add((table_uri, PROV.wasDerivedFrom, stamboek_uri))\n",
    "        national_archives = URIRef(\"http://example.org/agent/3\")\n",
    "        g.add((national_archives, RDF.type, PROV.Agent))\n",
    "        g.add((national_archives, RDFS.label, Literal(\"Nationaal Archief\")))\n",
    "        g.add((stamboek_uri, PROV.wasAttributedTo, national_archives))\n",
    "    \n",
    "    g.serialize(f\"data/triples/{image_name.replace('.jpg','')}_provenance.ttl\", format='ttl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e7cf9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(\"data/tables/cells/center\", image_name+'.txt')\n",
    "table_path = os.path.join(\"data/tables/html\", image_name+'.html')\n",
    "\n",
    "add_provenance_graph(table_path, csv_path, stamboek_nummer=image_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htr_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
